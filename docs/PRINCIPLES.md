# Maker — 반드시 지켜야 할 7가지 원칙

> 이 문서는 Maker 시스템 개발의 최상위 기준입니다.
> 모든 기능 설계, 코드 리뷰, 아키텍처 결정은 이 원칙을 따릅니다.
> 이 원칙을 위반하는 개발 지시는 경고 후 재검토되어야 합니다.

---

## 1. 통제는 항상 인간에게 있다

- AI는 실행 주체가 아니다.
- AI는 사용자가 설계한 구조 안에서만 호출된다.
- 자동 실행 전에는 항상 정책을 따른다.
- 권한은 명시적이다.
- "몰래 실행"은 존재하지 않는다.
- AI는 조수이고, 최종 책임자는 인간이다.

## 2. 기본값은 최소 권한이다

- 모든 위험한 권한은 기본적으로 OFF.
  - 파일 접근
  - 외부 전송
  - 일정 생성
  - 삭제 작업
- 사용자가 켜기 전까지는 아무 것도 하지 않는다.
- 편의보다 안전을 먼저 선택한다.

## 3. 데이터는 사용자 소유다

- Maker는 데이터를 흡수하지 않는다.
- 로컬 우선(Local-first)
- 명시적 데이터 전송 정책
- LLM Egress 통제
- SaaS는 데이터를 모은다. Maker는 데이터를 지킨다.

## 4. AI는 블랙박스가 아니다

- 모든 실행은 기록된다.
  - 실행 로그
  - 성공/실패 상태
  - 진단 시스템
  - 감사 기록(Audit)
- 사용자는 언제든지 "무슨 일이 일어났는가?"를 추적할 수 있어야 한다.

## 5. 의사결정 구조를 설계할 수 있어야 한다

- Maker는 봇을 소비하는 서비스가 아니다.
- 사용자는 설계한다:
  - 무엇을 수집할 것인가
  - 어떤 기준으로 판단할 것인가
  - 어떤 AI를 사용할 것인가
  - 언제 실행할 것인가
  - 어떤 결과만 승인할 것인가
- Maker는 실행 엔진이 아니라, 사고 구조 설계 도구다.

## 6. AI는 교체 가능해야 한다

- 특정 LLM에 종속되지 않는다.
  - OpenAI
  - Anthropic
  - Google
  - 호환 API
- LLM은 플러그인이다. 엔진은 Maker다.

## 7. 자동화는 인간을 대체하지 않는다

- Maker의 목적은 "완전 자동화"가 아니다.
- Human-in-the-loop 유지
- 승인 기반 실행
- 의사결정 보조 구조
- 자동화는 속도를 높인다. 판단은 인간이 한다.

---

## 한 문장 요약

**Maker는 AI를 더 강하게 만드는 시스템이 아니라, AI를 안전하게 통제할 수 있게 만드는 개인 자동화 OS다.**

이 7가지가 흔들리면 Maker는 그냥 또 하나의 자동화 툴이 됩니다.
이 7가지를 지키면, Maker는 "AI 시대의 통제 인프라"가 됩니다.
